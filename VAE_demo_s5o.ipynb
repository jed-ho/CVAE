{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160e0d6c",
   "metadata": {},
   "source": [
    "# Demonstration of anomaly detection with CVAE using DASHlink data\n",
    "\n",
    "**Author: Milad Memarzadeh (milad.memarzadeh@nasa.gov)**\n",
    "\n",
    "In this notebook, we first learn about CVAE (Convolutional Variational Auto-Encoder) and its different components. Then, we will apply CVAE to a dataset from DASHlink project (https://c3.ndc.nasa.gov/dashlink/projects/85/) for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b33fbd",
   "metadata": {},
   "source": [
    "### Part 1. What is a Variational Auto-Encoder?\n",
    "\n",
    "In this part, we first learn about the Variational Auto-Encoders (VAEs) and their use cases. VAEs are the generalization of Auto-Encoders that learn a lower-dimensional representation of the data using nonlinear transformations through neural networks in an unsupervised fashion. They are sometimes referred to as nonlinear Principal Component Analysis (PCA). The consists of two main components: (1) an encoder, $q_{\\phi}(z \\mid x)$, that maps the input data $ùëã$ to a lower-dimensional space, $ùëç$ (which is also called latent space), and (2) a decoder, $p_{\\theta}(x \\mid z)$ that reconstructs the original data $\\hat{X}$ by sampling from the low-dimensional latent space. Both encoder and decoder are parameterized by neural networks. \n",
    "\n",
    "VAEs use a regularizer to control the complexity of the distribution of the learned representations in the latent space. the main goal is that with proper regularization of the posterior distribution of the data in the latent space, i.e., $q_{\\phi}(z \\mid x)$, the model will be able to generalize better to an unseen data. They are trained based on two optimization objectives: (1) to optimize the quality/fidelity of the reconstructed data compared to the original ones, and (2) to regularize the posterior distribution of the latent space to not form a very complex distribution. This objective does not allow the model to overfit to the training data and be able to generalize to an unseen data with higher accuracy. The first objective is imposed by minimizing the reconstruction error, which can be calculated as a mean squared error between the input and the output, i.e., $\\lVert X - \\hat{X} \\rVert_{2}^{2}$ or maximizing the log-likelihood of the generated data. The second objective is imposed by minimizing the KL-divergence between the posterior distribution of the latent feature space and its prior distribution. In most cases, the prior/posteriors are assumed to form a multivariate Gaussian distribution. Given this, the overal objective function is defined as follows,\n",
    "\n",
    "$$\\mathcal{L}( \\theta, \\phi ; \\beta, x, z) = \\mathbb{E}_{q_{\\phi}(z \\mid x)}[\\log p_{\\theta}(x \\mid z) - \\beta \\text{KL}(q_{\\phi}(z \\mid x) \\Vert p(z))]$$\n",
    "\n",
    "where $\\beta$ controls the effect of regularization term on the overal training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5851a5",
   "metadata": {},
   "source": [
    "### Part 2. Convolutional VAE (CVAE)\n",
    "\n",
    "CVAE takes advantage of the convolutional neural networks to learn about the short-term as well as long-term temporal dependence in the input data. This is in comparison to fully connected neural networks that won't incorporate such temporal dependece. As a result, it is well-suited to work with multivariate time-series data. Figure below shows the illustration of the CVAE's architecture:\n",
    "\n",
    "\n",
    "<img src=\"cvae_arch.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "CVAE uses windowed time-series data as an input and applies series of convolutional operations with different filter sizes to take multiple local temporal dependencies into account. Then, the results of each series of convolutions are concatenated and mapped to the latent space. We use a similar architecture for both the encoder and the decoder. As a result, the decoder consists of a series of deconvolution and up-sampling with different filter sizes. Each branch of the encoder has four convolutional layers followed by a pooling layer, of which the number of input channels increases as the window size shrinks. Similarly, the decoder consists of four layers of de-convolution followed by an up-sampling layer, the number of input channels of which decreases as the window size expands.\n",
    "\n",
    "CVAE can be used for multiple purposes. It is an unsupervised reasoning model and does not require availability of labeled data for training. It is often used for:\n",
    "\n",
    "1. **Non-linear dimensionality reduction**: in this setting, it can be understood as a nonlinear Principal Component Analysis (PCA), where it uses series of nonlinear transformations to learn a lower-dimensional representation of the input data.\n",
    "\n",
    "2. **Anomaly detection**: if the training data consists mostly of nominal cases and few anomalies, one can imagine that training the model to reconstruct such data would only optimize this for the majority nominal data present in the training. Then, the reconstruction error can be used to detect those anomalous out-of-distribution data instances.\n",
    "\n",
    "\n",
    "3. **Data generation and augmentation**: once trained, CVAE can be used to generate and augment databases. One can perform random walks in the latent feature space and synthesize new data instances that are from the same distribution as the original input data.\n",
    "\n",
    "In this notebook, we will explore application of CVAE in finding anomalies in the final approach to landing of the commercial aircraft. We specifically focus on finding anomalies that are related to late deployment of the flaps, which results in a high speed and unstable approach to landing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f2c0d",
   "metadata": {},
   "source": [
    "### Part 3. Final approach to landing data from DASHlink project\n",
    "\n",
    "The is a Flight Operational Quality Assurance (FOQA) data of a commerical airline from DASHlink project (link at the top of the notebook). It comprises primarily 1-Hz recordings for each flight and covers a variety of systems. These include: the state and orientation of the aircraft, positions and inputs of the control surfaces, engine parameters, and auto pilot modes and corresponding states. The data is acquired in real time on-board the aircraft and downloaded by the airline once the aircraft has reached the destination gate. These time series are analyzed by domain experts, which derive threshold-based rules post-flight to flag known events and create labels. Each data instance is a 160 s long recording of 10 variables during the approach of the aircraft to landing (from a few seconds before an altitude of 1000 ft to a few seconds after an altitude of 500 ft). \n",
    "\n",
    "As mentioned before, we will focus on finding anomalies that are related to late deployment of the flaps, which results in a high speed and unstable approach to landing. Let us take a look at a sample of nominal and anomalous data instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a6137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b697530",
   "metadata": {},
   "source": [
    "Now, let us load the entirety of the training and testing data and take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb4fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (142100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "data_dir = 'C:/Users/jed95/Documents/GitHub/anomaly_detection/dataset/yahoo_s5/A2Benchmark'  # Adjust the path as necessary\n",
    "\n",
    "# Get the list of all CSV files in the directory\n",
    "file_list = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Load all files into a single DataFrame\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Data shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b70c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: timestamp     0\n",
      "value         0\n",
      "is_anomaly    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\", data.isnull().sum())\n",
    "\n",
    "# For simplicity, drop missing values (if any)\n",
    "data.dropna(inplace=True)\n",
    "scaler = MinMaxScaler()\n",
    "data['value'] = scaler.fit_transform(data['value'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93ee7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences shape: (142091, 10)\n",
      "Sequence labels shape: (142091,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(values, labels, sequence_length):\n",
    "    sequences = []\n",
    "    seq_labels = []\n",
    "    for i in range(len(values) - sequence_length + 1):\n",
    "        seq = values[i:i + sequence_length]\n",
    "        label = labels[i + sequence_length - 1]  # Label of the last element in the sequence\n",
    "        sequences.append(seq)\n",
    "        seq_labels.append(label)\n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "sequence_length = 10  # You can adjust this \n",
    "values = data['value'].values\n",
    "labels = data['is_anomaly'].values  # Assuming 'is_anomaly' is the label column\n",
    "\n",
    "sequences, seq_labels = create_sequences(values, labels, sequence_length)\n",
    "print(\"Sequences shape:\", sequences.shape)\n",
    "print(\"Sequence labels shape:\", seq_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8723d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for normal and anomalous sequences\n",
    "normal_indices = np.where(seq_labels == 0)[0]\n",
    "anomalous_indices = np.where(seq_labels == 1)[0]\n",
    "\n",
    "# Extract normal and anomalous sequences\n",
    "normal_sequences = sequences[normal_indices]\n",
    "normal_labels = seq_labels[normal_indices]\n",
    "\n",
    "anomalous_sequences = sequences[anomalous_indices]\n",
    "anomalous_labels = seq_labels[anomalous_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6518b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split normal data\n",
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(\n",
    "    normal_sequences, normal_labels, test_size=0.4, random_state=42, stratify=normal_labels)\n",
    "\n",
    "# Split anomalous data\n",
    "X_train_anomalous, X_test_anomalous, y_train_anomalous, y_test_anomalous = train_test_split(\n",
    "    anomalous_sequences, anomalous_labels, test_size=0.4, random_state=42, stratify=anomalous_labels)\n",
    "# Combine training data\n",
    "#X_train = np.concatenate([, ], axis=0)\n",
    "#y_train = np.concatenate([y_train_normal, ], axis=0)\n",
    "X_train = X_train_normal\n",
    "y_train = y_train_normal\n",
    "# Combine test data\n",
    "X_test = np.concatenate([X_test_normal, X_test_anomalous], axis=0)\n",
    "y_test = np.concatenate([y_test_normal, y_test_anomalous], axis=0)\n",
    "# Shuffle training data\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "# Convert training data to tensors\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "\n",
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf1c2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels  # Now labels are provided for all data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return X, y\n",
    "\n",
    "        return x\n",
    "\n",
    "batch_size = 64  # Adjust as needed\n",
    "\n",
    "# Training data loader\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #TODO adjust Shuffle training data? \n",
    "\n",
    "# Test data loader\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a8bd3",
   "metadata": {},
   "source": [
    "### Part 4. Training CVAE\n",
    "\n",
    "In this section, we show you steps that needs to be take to train the CVAE. Although, we will only load up a trained model later on, we will show you details of the steps here:\n",
    "\n",
    "\n",
    "Let us first start with preparing the data loaders for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9599316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from source.modelsVAE import *\n",
    "#from source.utils import *\n",
    "##cuda = torch.cuda.is_available()\n",
    "## PyTorch wants the number of params to be the first dimension and the window size to be the second dimension\n",
    "#x_train = np.transpose(x_train, axes=(0, 2, 1))\n",
    "#x_test = np.transpose(x_test, axes=(0, 2, 1))\n",
    "#\n",
    "## Preparing training and testing datasets\n",
    "#train = Dataset(x_train)\n",
    "#test = Dataset(x_test)\n",
    "#\n",
    "## Preparing the data loader\n",
    "#batch_size = 128\n",
    "#train_data, test_data = get_dataset(train, test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431aaa32",
   "metadata": {},
   "source": [
    "Now let us configure a model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4345488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cpu\n",
      "Number of Epochs:  10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x1 and 50x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# training or loading the trained model:\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m---> 26\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloading_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#model = model.to('cpu')\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload((loading_dir\u001b[38;5;241m+\u001b[39mmodel_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     31\u001b[0m                           map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\jed95\\Documents\\GitHub\\CVAE\\source\\utils.py:108\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, model_name, train_data, valid_data, save_dir, metric, beta, num_epochs, save, verbose)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda: x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# obtaining the reconstruction for the mini-batch\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# calculating the likelihood with the specified metric by user\u001b[39;00m\n\u001b[0;32m    111\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlikelihood_loss(reconstruction, x, metric)\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jed95\\Documents\\GitHub\\CVAE\\source\\modelsVAE.py:134\u001b[0m, in \u001b[0;36mVAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Encode input and sample from latent space\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     z, z_mu, z_log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Compute KL divergence\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_div \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkld_((z_mu, z_log_var))\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jed95\\Documents\\GitHub\\CVAE\\source\\modelsVAE.py:61\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Pass through fully connected layers with ReLU activation\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers:\n\u001b[1;32m---> 61\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Perform reparameterization to get latent variables\u001b[39;00m\n\u001b[0;32m     63\u001b[0m z_sample, mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(x)\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jed95\\.conda\\envs\\cvae\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x1 and 50x512)"
     ]
    }
   ],
   "source": [
    "from source.modelsVAE import VAE\n",
    "from source.utils import train_model\n",
    "num_epochs = 10 # Number of epochs for training\n",
    "latent_dim = 32 # dimension of the latent space\n",
    "beta = 0.001 # value of beta that controls the regularization\n",
    "metric = 'BCE' # choice of metric for calculating reconstruction error\n",
    "training = 1 # whether to train the model or load a trained one\n",
    "# Model parameters\n",
    "\n",
    "num_param = 1\n",
    "window_size = 50\n",
    "scale_flag = 0  # Use Sigmoid activation since data is scaled to [0, 1]\n",
    "loading_dir = './models/'\n",
    "# Naming the model for saving\n",
    "model_name = (\"s5_VAE_l_\"+(str(latent_dim))+\"_beta_\"+(str(beta))+\n",
    "              \"_batch_\"+str(batch_size)+\"_metric_\"+metric)\n",
    "\n",
    "# initiating the model\n",
    "model = VAE(latent_dim=latent_dim, num_param=num_param, window_size=window_size, scale_flag=scale_flag)\n",
    "\n",
    "# setting up the optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "# training or loading the trained model:\n",
    "if training:\n",
    "    model = train_model(model, optimizer, model_name, X_train_tensor, X_test_tensor, loading_dir,\n",
    "                   metric, beta, num_epochs, save=True, verbose=1)\n",
    "    #model = model.to('cpu')\n",
    "else:\n",
    "    model.load_state_dict(torch.load((loading_dir+model_name+\".pth\"),\n",
    "                          map_location=torch.device('cpu')))\n",
    "    print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f665b01",
   "metadata": {},
   "source": [
    "### Part 5. Training statistics\n",
    "\n",
    "We have also saved the trajectory of training losses that we can visualize to make sure that the model has trained properly:\n",
    "\n",
    "**Note:** if you train a new model, this should be saved in your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b216f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_traj = np.load(loading_dir+model_name+\"_training_loss.npz\")\n",
    "\n",
    "total_loss = training_traj['training_total_loss']\n",
    "rec_loss = training_traj['training_rec_loss']\n",
    "kl_loss = training_traj['training_kl_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Total Loss\", fontsize=12)\n",
    "plt.plot(range(num_epochs), total_loss)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstruction Loss\", fontsize=12)\n",
    "plt.plot(range(num_epochs), rec_loss)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.xlabel(\"Epochs of training\", fontsize=12)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"KL Loss\", fontsize=12)\n",
    "plt.plot(range(num_epochs), kl_loss)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3951a",
   "metadata": {},
   "source": [
    "### Part 6. Performance evaluation on the testing set\n",
    "\n",
    "Now that we have trained a model, we will use it to identify anomalies in the testing set and evaluate how accurate we are. First, we need to calculate the threshold for anomaly detection based on reconstruction error of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6284fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding a threshold for anomaly detection \n",
    "\n",
    "## Please note that this step might take a while. A smaller num_sample will\n",
    "### speed up this step with a trade-off of a less accurate estimate of the threshold.\n",
    "#### for the sake of time, we have saved the results of this step and will load it here:\n",
    "\n",
    "scale = 2 # how many std from mean should we use to set up the threshold\n",
    "\n",
    "train_anomaly_score = find_score(model, x_train, metric, num_sample=50)\n",
    "np.savez_compressed(loading_dir+model_name+\"_train_scores\", scores=train_anomaly_score)\n",
    "\n",
    "train_anomaly_score = np.load(loading_dir+model_name+\"_train_scores.npz\")['scores']\n",
    "threshold = np.mean(train_anomaly_score) + scale * np.std(train_anomaly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62619074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we find the threshold, we can use it to identify anomalies in the test set\n",
    "\n",
    "model_preds = np.zeros(np.shape(x_test)[0])\n",
    "\n",
    "# calculating the anomaly scores on the test set (again, for the sake of time, we will load this)\n",
    "test_anomaly_score = find_score(model, x_test, metric, num_sample=50)\n",
    "np.savez_compressed(loading_dir+model_name+\"_test_scores.npz\", scores=test_anomaly_score)\n",
    "\n",
    "test_anomaly_score = np.load(loading_dir+model_name+\"_test_scores.npz\")['scores']\n",
    "model_preds[test_anomaly_score > threshold] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0c45",
   "metadata": {},
   "source": [
    "Graph below, shows the histogram of the anomaly scores for the nominal and anomalous data samples in the testing set. We can see that for the nominal data, the score is generally lower and less variant, while it is much more variant and generally higher for the anomalous data samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_nominal = np.where(y_test==0)[0]\n",
    "ind_anomaly = np.where(y_test==1)[0]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(test_anomaly_score[ind_nominal], bins=50, alpha=0.5, color='Green', label='Nominal')\n",
    "plt.hist(test_anomaly_score[ind_anomaly], bins=50, alpha=0.8, color='Orange', label='Anomalous')\n",
    "plt.vlines(threshold, 0, 300, color='blue', linestyle='dashed', alpha=0.5, label='Threshold')\n",
    "plt.ylim(0, 260)\n",
    "plt.xlabel(\"Anomaly Score\", fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175ea66",
   "metadata": {},
   "source": [
    "Below numbers are the precision, recall and F1-score of the performance on the testing set. They are defined as follow,\n",
    "\n",
    "\n",
    "$$ \\text{precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "$$ \\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "where $TP$ is true positive: anomalies that are correctly identified, $FP$ is false positive (or false alarms):\n",
    "anomalies that are incorrectly identified, and $FN$ is false negative, or anomalies that are missed and classified as nominal by mistake.\n",
    "\n",
    "F1-score is the harmonic mean of the two above metrics and it is easier to choose, because one can makes the decision based on only one metric:\n",
    "\n",
    "$$ \\text{F1-score} = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "info = precision_recall_fscore_support(y_test, model_preds, pos_label=1)\n",
    "print(\"Precision = {}%, recall = {}% and F1-score = {}%\".format(np.round(info[0][1]*100, 2),\n",
    "                                                                np.round(info[1][1]*100, 2),\n",
    "                                                                np.round(info[2][1]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc344bd",
   "metadata": {},
   "source": [
    "Below, we also visualize the confusion matrix that shows the correct and wrong classifications for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, model_preds)\n",
    "\n",
    "\n",
    "FONT = 14\n",
    "classes = ['Nominal', 'Anomaly']\n",
    "#plt.figure(figsize=(8, 8))\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "fig, ax1 = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "im = ax1.imshow(cm, cmap=cmap)\n",
    "ax1.set_title(\"Confusion Matrix\", fontsize=FONT)\n",
    "ax1.set_xticks(np.arange(len(classes)))\n",
    "ax1.set_xticklabels(\"\")\n",
    "ax1.set_yticks(np.arange(len(classes)))\n",
    "ax1.set_xticklabels(classes, rotation=0)\n",
    "ax1.set_ylim(len(classes)-0.5, -0.5)\n",
    "ax1.set_yticklabels(classes)\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        if cm[j, i] > 1000:\n",
    "            cc = 'white'\n",
    "        else:\n",
    "            cc = 'black'\n",
    "        text = ax1.text(i, j, cm[j, i],\n",
    "                       ha=\"center\", va=\"center\", color=cc, fontsize=FONT)\n",
    "ax1.set_ylabel(\"Actual Class\", fontsize=FONT)\n",
    "ax1.set_xlabel(\"Predicted Class\", fontsize=FONT)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=FONT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5a421",
   "metadata": {},
   "source": [
    "### Part 7. Structure of the data in the latent feature space\n",
    "\n",
    "In this part, we use t-Stochastic Neighbour Embedding (t-SNE) to visualize the 32-dimensional latent feature space in 2D and color code each data sample by the class it belongs to in order to better understand the structure of the learned feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf74ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model.eval()\n",
    "\n",
    "# obtaining latent variables\n",
    "z_test = model.encoder(torch.from_numpy(x_test))[0].detach().numpy()\n",
    "\n",
    "# using t-SNE to map latnet variables to 2D\n",
    "tsne_test = TSNE(n_components=2, perplexity=50, init='pca', random_state=33).fit_transform(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af172bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['Green', 'Orange']\n",
    "labels = ['Nominal', 'Anomaly']\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Color-coded based on true labels\", fontsize=14)\n",
    "for i in range(2):\n",
    "    indices = np.where(y_test==i)[0]\n",
    "    plt.scatter(tsne_test[indices, 0], tsne_test[indices, 1], label=labels[i], c=colors[i], alpha=0.5)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Color-coded based on model prediction\", fontsize=14)\n",
    "for i in range(2):\n",
    "    indices = np.where(model_preds==i)[0]\n",
    "    plt.scatter(tsne_test[indices, 0], tsne_test[indices, 1], label=labels[i], c=colors[i], alpha=0.5)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
