{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160e0d6c",
   "metadata": {},
   "source": [
    "# Demonstration of anomaly detection with CVAE using DASHlink data\n",
    "\n",
    "**Author: Milad Memarzadeh (milad.memarzadeh@nasa.gov)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f2c0d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from source.modelsCondVAECompress import *\n",
    "from source.utilsCondVAEs5 import *\n",
    "from itertools import combinations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758118c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "train_learning_rate = 1e-4\n",
    "finetune_learning_rate = 1e-5\n",
    "train_num_epochs = 50\n",
    "finetune_num_epochs = 5\n",
    "\n",
    "latent_dim = 10\n",
    "batch_size = 64\n",
    "window_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b697530",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    data_dir = 'C:/Users/jed95/Documents/GitHub/anomaly_detection/dataset/yahoo_s5/A4Benchmark/'\n",
    "else:\n",
    "    data_dir = '/home/adlink3/Downloads/yahoo_s5/A4Benchmark/'\n",
    "save_dir=\"./compress/A4/\"\n",
    "file_list = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Data shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values:\", data.isnull().sum())\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data['value'] = scaler.fit_transform(data['value'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f665b01",
   "metadata": {},
   "source": [
    "# Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b216f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(values, labels, window_size, step=1):\n",
    "    sequences = []\n",
    "    seq_labels = []\n",
    "    for i in range(0, len(values) - window_size + 1, step):\n",
    "        seq = values[i:i + window_size]\n",
    "        # If any label in the sequence is anomalous (e.g., 1), set the sequence label as anomalous\n",
    "        label = 1 if any(labels[i:i + window_size]) else 0\n",
    "        sequences.append(seq)\n",
    "        seq_labels.append(label)\n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "\n",
    "sequences, seq_labels = create_sequences(data['value'].values, data['anomaly'].values, window_size=window_size)\n",
    "print(\"Sequences shape:\", sequences.shape)\n",
    "print(\"Sequence labels shape:\", seq_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0c45",
   "metadata": {},
   "source": [
    "# Split data into labeled and unlabeled sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6284fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal_indices = np.where(seq_labels == 0)[0]\n",
    "anomalous_indices = np.where(seq_labels == 1)[0]\n",
    "\n",
    "normal_sequences = sequences[normal_indices]\n",
    "normal_labels = seq_labels[normal_indices]\n",
    "\n",
    "anomalous_sequences = sequences[anomalous_indices]\n",
    "anomalous_labels = seq_labels[anomalous_indices]\n",
    "print(normal_sequences.shape)\n",
    "print(anomalous_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb09988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(\n",
    "    normal_sequences, normal_labels, test_size=0.6, random_state=42, stratify=normal_labels)\n",
    "X_train_normal, X_val_normal, y_train_normal, y_val_normal = train_test_split(\n",
    "    X_train_normal, y_train_normal, test_size=0.5, random_state=42, stratify=y_train_normal)\n",
    "\n",
    "\n",
    "X_train_anomalous, X_test_anomalous, y_train_anomalous, y_test_anomalous = train_test_split(\n",
    "    anomalous_sequences, anomalous_labels, test_size=0.6, random_state=42, stratify=anomalous_labels)\n",
    "X_train_anomalous, X_val_anomalous, y_train_anomalous, y_val_anomalous = train_test_split(\n",
    "    X_train_anomalous, y_train_anomalous, test_size=0.5, random_state=42, stratify=y_train_anomalous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_normal, X_train_anomalous], axis=0)\n",
    "y_train = np.concatenate([y_train_normal, y_train_anomalous], axis=0)\n",
    "\n",
    "X_val = np.concatenate([X_val_normal, X_val_anomalous], axis=0)\n",
    "y_val = np.concatenate([y_val_normal, y_val_anomalous], axis=0)\n",
    "\n",
    "X_test = np.concatenate([X_test_normal, X_test_anomalous], axis=0)\n",
    "y_test = np.concatenate([y_test_normal, y_test_anomalous], axis=0)\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1beef",
   "metadata": {},
   "source": [
    "# Convert Data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val).float()\n",
    "y_val_tensor = torch.tensor(y_val).long()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50dc79a",
   "metadata": {},
   "source": [
    "# Create Data Loaders for Labeled and Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af172bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels  # Now labels are provided for all data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) #TODO adjust Shuffle training data? \n",
    "full_train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "val_dataset = TimeSeriesDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e288d",
   "metadata": {},
   "source": [
    "# Instantiate and Train the Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            z, x_rec, class_logits = model(data)\n",
    "            \n",
    "            # Compute classification loss\n",
    "            loss = criterion(class_logits, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Compute accuracy\n",
    "            preds = class_logits.argmax(dim=1)\n",
    "            total_correct += (preds == target).sum().item()\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "num_param = 1    # Since we have univariate time series\n",
    "num_classes = 2 \n",
    "scale_flag = 0   # Use Sigmoid activation in the decoder\n",
    "\n",
    "results = {}\n",
    "\n",
    "print('Starting k-fold cross-validation...')\n",
    "time_start = time.time()\n",
    "for fold, (train_idx, val2_idx) in enumerate(skf.split(np.zeros(len(y_train_tensor)), y_train_tensor.cpu().numpy())):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "    model_name=\"CondVAE_model\"+str(fold+1)\n",
    "    # Create data loaders for the current fold\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val2_subsampler = torch.utils.data.SubsetRandomSampler(val2_idx)\n",
    "    \n",
    "    train_loader = DataLoader(full_train_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    val2_loader = DataLoader(full_train_dataset, batch_size=batch_size, sampler=val2_subsampler)\n",
    "    \n",
    "    model = VAE(latent_dim, num_param, window_size, num_classes, scale_flag).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=train_learning_rate)\n",
    "    \n",
    "    model = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    num_epochs=train_num_epochs,\n",
    "    save=True,\n",
    "    save_dir=save_dir,\n",
    "    model_name=model_name)\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_loss, val_acc = evaluate_model(model, val2_loader)\n",
    "    \n",
    "    # Save the results for this fold\n",
    "    results[fold] = {'val_loss': val_loss, 'val_acc': val_acc}\n",
    "    \n",
    "    print(f'Fold {fold+1} Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "time_end = time.time()\n",
    "print(f'Total time taken for k-fold cross-validation: {time_end - time_start} seconds')\n",
    "buffer = io.BytesIO()\n",
    "torch.save(model.state_dict(), buffer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(model_name, save_dir):\n",
    "    training_traj = np.load(save_dir+model_name+\"_training_loss.npz\")\n",
    "\n",
    "    total_loss = training_traj['training_total_loss']\n",
    "    rec_loss = training_traj['training_rec_loss']\n",
    "    kl_loss = training_traj['training_kl_loss']\n",
    "    class_loss = training_traj['training_class_loss']\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.suptitle(model_name, fontsize=16)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title(\"Total Loss\", fontsize=12)\n",
    "    plt.plot(range(len(total_loss)), total_loss)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title(\"Reconstruction Loss\", fontsize=12)\n",
    "    plt.plot(range(len(total_loss)), rec_loss)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title(\"KL Loss\", fontsize=12)\n",
    "    plt.plot(range(len(total_loss)), kl_loss)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title(\"Classification Loss\", fontsize=12)\n",
    "    plt.plot(range(len(total_loss)), class_loss)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "for fold in range(k_folds):\n",
    "    plot_training_loss(\"CondVAE_model\"+str(fold+1), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Anomalous\"]).plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019aa278",
   "metadata": {},
   "source": [
    "# Initialize 3 new models for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86116d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.seek(0) \n",
    "model_medium = VAE(latent_dim, num_param, window_size, num_classes, scale_flag).to(device)\n",
    "model_medium.load_state_dict(torch.load(buffer))\n",
    "model_medium = model_medium.to(device)\n",
    "\n",
    "buffer.seek(0)\n",
    "model_strong = VAE(latent_dim, num_param, window_size, num_classes, scale_flag).to(device)\n",
    "model_strong.load_state_dict(torch.load(buffer))\n",
    "model_strong = model_strong.to(device)\n",
    "buffer.seek(0)\n",
    "model_random = VAE(latent_dim, num_param, window_size, num_classes, scale_flag).to(device)\n",
    "model_random.load_state_dict(torch.load(buffer))\n",
    "model_random = model_random.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809e18a",
   "metadata": {},
   "source": [
    "# Verify the 3 new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a flag\n",
    "models_identical = True\n",
    "original_state_dict = model.state_dict()\n",
    "loaded_state_dict = model_medium.state_dict()\n",
    "# Compare each parameter\n",
    "for key in original_state_dict:\n",
    "    original_param = original_state_dict[key]\n",
    "    loaded_param = loaded_state_dict[key]\n",
    "    if not torch.equal(original_param, loaded_param):\n",
    "        print(f\"Mismatch found at layer: {key}\")\n",
    "        models_identical = False\n",
    "        break\n",
    "\n",
    "if models_identical:\n",
    "    print(\"The saved and loaded models are identical.\")\n",
    "else:\n",
    "    print(\"The models are not identical.\")\n",
    "# Initialize a flag\n",
    "models_identical = True\n",
    "original_state_dict = model_random.state_dict()\n",
    "loaded_state_dict = model_medium.state_dict()\n",
    "# Compare each parameter\n",
    "for key in original_state_dict:\n",
    "    original_param = original_state_dict[key]\n",
    "    loaded_param = loaded_state_dict[key]\n",
    "    if not torch.equal(original_param, loaded_param):\n",
    "        print(f\"Mismatch found at layer: {key}\")\n",
    "        models_identical = False\n",
    "        break\n",
    "\n",
    "if models_identical:\n",
    "    print(\"The saved and loaded models are identical.\")\n",
    "else:\n",
    "    print(\"The models are not identical.\")\n",
    "# Initialize a flag\n",
    "models_identical = True\n",
    "original_state_dict = model.state_dict()\n",
    "loaded_state_dict = model_strong.state_dict()\n",
    "# Compare each parameter\n",
    "for key in original_state_dict:\n",
    "    original_param = original_state_dict[key]\n",
    "    loaded_param = loaded_state_dict[key]\n",
    "    if not torch.equal(original_param, loaded_param):\n",
    "        print(f\"Mismatch found at layer: {key}\")\n",
    "        models_identical = False\n",
    "        break\n",
    "\n",
    "if models_identical:\n",
    "    print(\"The saved and loaded models are identical.\")\n",
    "else:\n",
    "    print(\"The models are not identical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06774dd",
   "metadata": {},
   "source": [
    "# Evaluate the Model and Detect Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores(model, data_loader):\n",
    "    model.eval()\n",
    "    rec_errors = []\n",
    "    anomaly_probs = []\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch = X_batch.unsqueeze(1).to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            z, x_rec, class_logits = model(X_batch)\n",
    "            print(\"X_batch shape:\", X_batch.shape)\n",
    "            print(\"x_rec shape:\", x_rec.shape)\n",
    "            print(\"z shape:\", z.shape)\n",
    "\n",
    "            y_probs = F.softmax(class_logits, dim=1)\n",
    "\n",
    "            # Reconstruction error\n",
    "            rec_error = torch.mean((X_batch - x_rec) ** 2, dim=[1, 2])\n",
    "\n",
    "            # Classification probability for anomaly class\n",
    "            anomaly_prob = y_probs[:, 1]\n",
    "\n",
    "            # Combine scores\n",
    "            #anomaly_score = rec_error * anomaly_prob\n",
    "           \n",
    "            rec_errors.extend(rec_error.cpu().numpy())\n",
    "            anomaly_probs.extend(anomaly_prob.cpu().numpy())\n",
    "            true_labels.extend(y_batch.cpu().numpy())\n",
    "            predictions.extend(torch.argmax(class_logits, dim=1).cpu().numpy())\n",
    "            latents.append(z.cpu())\n",
    "            \n",
    "    latent_tensor = torch.cat(latents, dim=0)          # shape: (N_samples, latent_dim)\n",
    "    # 1) PyTorch\n",
    "    torch.save(latent_tensor, save_dir+'latent_vectors.pt')\n",
    "    # 2) NumPy\n",
    "    np.save(save_dir+'latent_vectors.npy', latent_tensor.numpy())\n",
    "    # 3) CSV\n",
    "    df = pd.DataFrame(latent_tensor.numpy())\n",
    "    df.to_csv(save_dir+'latent_vectors.csv', index=False)\n",
    "    print(f\"Saved {latent_tensor.shape[0]} latent vectors to disk.\")\n",
    "    return np.array(rec_errors), np.array(anomaly_probs), np.array(true_labels), np.array(predictions)\n",
    "\n",
    "# Compute anomaly scores\n",
    "train_rec_errors, train_anomaly_probs, train_true_labels, train_predictions = compute_anomaly_scores(model, train_loader)\n",
    "val_rec_errors, val_anomaly_probs, val_true_labels, val_predictions = compute_anomaly_scores(model, val_loader)\n",
    "test_rec_errors, test_anomaly_probs, test_true_labels, test_predictions = compute_anomaly_scores(model, test_loader)\n",
    "\n",
    "plot_confusion_matrix(test_true_labels, test_predictions)\n",
    "info = precision_recall_fscore_support(test_true_labels, test_predictions, pos_label=1)\n",
    "print(\"Precision = {}%, recall = {}% and F1-score = {}%\".format(np.round(info[0][1]*100, 2),\n",
    "                                                                np.round(info[1][1]*100, 2),\n",
    "                                                                np.round(info[2][1]*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(val_anomaly_probs)), val_anomaly_probs, alpha=0.7, c=(val_true_labels!=val_predictions), cmap='coolwarm')\n",
    "plt.title(\"Scatter Plot of Validation Anomaly Scores\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(val_rec_errors, val_anomaly_probs, alpha=0.7, c=(val_true_labels==val_predictions), cmap='coolwarm')\n",
    "plt.title(\"Scatter Plot of Validation Anomaly Scores with Reconstruction Errors\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(val_anomaly_probs, vert=False)\n",
    "plt.title(\"Box Plot of Validation Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(val_anomaly_probs, bins=20, alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Histogram of Validation Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(val_rec_errors)), val_rec_errors, alpha=0.7, c=val_true_labels, cmap='coolwarm')\n",
    "plt.title(\"Scatter Plot of Validation Anomaly Scores (true labels)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(val_rec_errors)), val_rec_errors, alpha=0.7, c=val_predictions, cmap='coolwarm')\n",
    "plt.title(\"Scatter Plot of Validation Anomaly Scores (predictions)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(val_rec_errors)), val_rec_errors, alpha=0.7, c=val_anomaly_probs, cmap='coolwarm')\n",
    "plt.title(\"Scatter Plot of Validation Anomaly Scores (anomalous probability)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(val_rec_errors, vert=False)\n",
    "plt.title(\"Box Plot of Validation Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(val_rec_errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Histogram of Validation Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ea362",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine thresholds\n",
    "#lower_percentile = 62.5\n",
    "#upper_percentile = 37.5\n",
    "#lower_threshold = np.percentile(val_anomaly_probs, lower_percentile)\n",
    "#upper_threshold = np.percentile(val_anomaly_probs, upper_percentile)\n",
    "\n",
    "\n",
    "# Select medium-score data\n",
    "medium_score_indices = np.where((val_anomaly_probs >= 0.05) & (val_anomaly_probs <= 0.95))[0]\n",
    "X_medium = X_val[medium_score_indices]\n",
    "y_medium = y_val[medium_score_indices]\n",
    "print(\"Medium-score data shape:\", X_medium.shape, y_medium.shape)\n",
    "X_medium_tensor = torch.tensor(X_medium).float()\n",
    "y_medium_tensor = torch.tensor(y_medium).long()\n",
    "# data loader\n",
    "medium_dataset = TimeSeriesDataset(X_medium_tensor, y_medium_tensor)\n",
    "medium_loader = DataLoader(medium_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine thresholds\n",
    "#lower_percentile = 12.5\n",
    "#upper_percentile = 87.5\n",
    "#lower_threshold = np.percentile(val_anomaly_probs, lower_percentile)\n",
    "#upper_threshold = np.percentile(val_anomaly_probs, upper_percentile)\n",
    "\n",
    "# Select strong-score data\n",
    "strong_score_indices = np.where((val_anomaly_probs <= 0.01) | (val_anomaly_probs >= 0.99))[0]\n",
    "X_strong = X_val[strong_score_indices]\n",
    "y_strong = y_val[strong_score_indices]\n",
    "print(\"Strong-score data shape:\", X_strong.shape, y_strong.shape)\n",
    "X_strong_tensor = torch.tensor(X_strong).float()\n",
    "y_strong_tensor = torch.tensor(y_strong).long()\n",
    "# data loader\n",
    "strong_dataset = TimeSeriesDataset(X_strong_tensor, y_strong_tensor)\n",
    "strong_loader = DataLoader(strong_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b63f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the fraction of data to select\n",
    "sample_fraction = 0.25\n",
    "total_samples = len(val_anomaly_probs)\n",
    "sample_size = int(sample_fraction * total_samples)\n",
    "\n",
    "# Randomly select unique indices without replacement\n",
    "random_score_indices = np.random.choice(total_samples, size=sample_size, replace=False)\n",
    "\n",
    "# Select the corresponding data and labels\n",
    "X_random = X_val[random_score_indices]\n",
    "y_random = y_val[random_score_indices]\n",
    "print(\"Random data shape:\", X_random.shape, y_random.shape)\n",
    "# Convert to PyTorch tensors\n",
    "X_random_tensor = torch.tensor(X_random).float()\n",
    "y_random_tensor = torch.tensor(y_random).long()\n",
    "\n",
    "# Create the dataset and data loader\n",
    "random_dataset = TimeSeriesDataset(X_random_tensor, y_random_tensor)\n",
    "random_loader = DataLoader(random_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune the model\n",
    "model_name = \"model_medium\"\n",
    "optimizer = optim.Adam(model_medium.parameters(), lr=finetune_learning_rate)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-7)\n",
    "model_medium = train_model(model_medium, optimizer, medium_loader, num_epochs=finetune_num_epochs, model_name=\n",
    "                           model_name, save_dir=save_dir, save=True)\n",
    "plot_training_loss(model_name, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba323de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_strong.parameters(), lr=finetune_learning_rate)\n",
    "model_name = \"model_strong\"\n",
    "model_strong = train_model(model_strong, optimizer, strong_loader, num_epochs=finetune_num_epochs, model_name=model_name, save_dir=save_dir, save=True)\n",
    "plot_training_loss(model_name, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model_random\"\n",
    "optimizer = optim.Adam(model_random.parameters(), lr=finetune_learning_rate)\n",
    "model_random = train_model(model_random, optimizer, random_loader, num_epochs=finetune_num_epochs, model_name=model_name, save_dir=save_dir, save=True)\n",
    "plot_training_loss(model_name, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7369e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined and initialized your models:\n",
    "# model, model_medium, model_random, model_strong\n",
    "\n",
    "# Dictionary of models with their names for easy reference\n",
    "models = {\n",
    "    'model': model,\n",
    "    'model_medium': model_medium,\n",
    "    'model_random': model_random,\n",
    "    'model_strong': model_strong\n",
    "}\n",
    "\n",
    "# Generate all possible unique pairs of models\n",
    "model_pairs = list(combinations(models.items(), 2))\n",
    "\n",
    "# Lists to keep track of identical and different model pairs\n",
    "identical_pairs = []\n",
    "different_pairs = []\n",
    "\n",
    "# Function to compare two models\n",
    "def compare_models(model1, model2, name1, name2):\n",
    "    state_dict1 = model1.state_dict()\n",
    "    state_dict2 = model2.state_dict()\n",
    "    \n",
    "    # First, check if both models have the same set of keys (layers)\n",
    "    keys1 = set(state_dict1.keys())\n",
    "    keys2 = set(state_dict2.keys())\n",
    "    \n",
    "    if keys1 != keys2:\n",
    "        missing_in_1 = keys2 - keys1\n",
    "        missing_in_2 = keys1 - keys2\n",
    "        if missing_in_1:\n",
    "            \n",
    "            print(f\"Model '{name1}' is missing layers: {missing_in_1}\")\n",
    "        if missing_in_2:\n",
    "            \n",
    "            print(f\"Model '{name2}' is missing layers: {missing_in_2}\")\n",
    "        return False  # Layers mismatch implies models are different\n",
    "    \n",
    "    # Compare each parameter tensor\n",
    "    for key in state_dict1:\n",
    "        param1 = state_dict1[key]\n",
    "        param2 = state_dict2[key]\n",
    "        \n",
    "        if not torch.equal(param1, param2):\n",
    "            #print(f\"Mismatch found in layer '{key}' between '{name1}' and '{name2}'.\")\n",
    "            return False  # Found a mismatch\n",
    "    \n",
    "    return True  # All parameters match\n",
    "\n",
    "# Iterate through each pair and compare\n",
    "for (name1, model1), (name2, model2_medium) in model_pairs:\n",
    "    print(f\"Comparing '{name1}' with '{name2}':\")\n",
    "    are_identical = compare_models(model1, model2_medium, name1, name2)\n",
    "    \n",
    "    if are_identical:\n",
    "        identical_pairs.append((name1, name2))\n",
    "        print(f\"--> '{name1}' and '{name2}' are IDENTICAL.\\n\")\n",
    "    else:\n",
    "        different_pairs.append((name1, name2))\n",
    "        print(f\"--> '{name1}' and '{name2}' are DIFFERENT.\\n\")\n",
    "\n",
    "# Summary of results\n",
    "print(\"=== Comparison Summary ===\\n\")\n",
    "\n",
    "if identical_pairs:\n",
    "    print(\"Identical Model Pairs:\")\n",
    "    for name1, name2 in identical_pairs:\n",
    "        print(f\" - {name1} and {name2}\")\n",
    "else:\n",
    "    print(\"No identical model pairs found.\")\n",
    "\n",
    "print()\n",
    "\n",
    "if different_pairs:\n",
    "    print(\"Different Model Pairs:\")\n",
    "    for name1, name2 in different_pairs:\n",
    "        print(f\" - {name1} and {name2}\")\n",
    "else:\n",
    "    print(\"No different model pairs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec_errors, test_anomaly_probs, test_true_labels, test_predictions = compute_anomaly_scores(model_medium, test_loader)\n",
    "\n",
    "plot_confusion_matrix(test_true_labels, test_predictions)\n",
    "info = precision_recall_fscore_support(test_true_labels, test_predictions, pos_label=1)\n",
    "print(\"Precision = {}%, recall = {}% and F1-score = {}%\".format(np.round(info[0][1]*100, 2),\n",
    "                                                                np.round(info[1][1]*100, 2),\n",
    "                                                                np.round(info[2][1]*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec_errors, test_anomaly_probs, test_true_labels, test_predictions = compute_anomaly_scores(model_strong, test_loader)\n",
    "plot_confusion_matrix(test_true_labels, test_predictions)\n",
    "info = precision_recall_fscore_support(test_true_labels, test_predictions, pos_label=1)\n",
    "print(\"Precision = {}%, recall = {}% and F1-score = {}%\".format(np.round(info[0][1]*100, 2),\n",
    "                                                                np.round(info[1][1]*100, 2),\n",
    "                                                                np.round(info[2][1]*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec_errors, test_anomaly_probs, test_true_labels, test_predictions = compute_anomaly_scores(model_random, test_loader)\n",
    "plot_confusion_matrix(test_true_labels, test_predictions)\n",
    "info = precision_recall_fscore_support(test_true_labels, test_predictions, pos_label=1)\n",
    "print(\"Precision = {}%, recall = {}% and F1-score = {}%\".format(np.round(info[0][1]*100, 2),\n",
    "                                                                np.round(info[1][1]*100, 2),\n",
    "                                                                np.round(info[2][1]*100, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
